{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "sv",
      "targetLang": "en",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "Kopia av Laboration 2 - inlämning del 2 .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f4wg7zCSajF_",
        "vrfxdRl8ajGC",
        "7C5pg93tajGC",
        "8F_kNrkpajGE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikniknikm/Laboration_1/blob/master/Kopia_av_Laboration_2_inl%C3%A4mning_del_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebzA6HddajFp"
      },
      "source": [
        "# Laboration 2 - inlämning del 2 Analys av tweets från bokmässan\n",
        "\n",
        "## Attribution David Johnsson, Uppsala University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ctXum6ajF3"
      },
      "source": [
        "Starta med att ladda in följande moduler och sätt upp visualiseringsmiljön för matplotlib\n",
        "\n",
        "1. `pandas` \n",
        "2. `textmining` \n",
        "Funktioner för statistisk textmining, fokuserad på bag-of-words model (som ni inte behöver sätta er in för denna kurs.f För den nyfikne eller vetgirige finns enkla förklaringar exempelvis [här](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) eller [här](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/), en enkel tutorial finns också [här](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)) \n",
        "3. `wordcloud` - En visualiseringsmodul för att skapa ordmoln, vilket vi gör i denna laboration.\n",
        "4. `matplotlib` \n",
        "5. `sklearn` -  Scikit-learn,ett pythonbibliotek för maskininlärningsalgoritmer, den kommer vi använda mycket i både laboration 3 och 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeO5zn6iajF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4a571b-7ad2-403f-dcbf-f8d33fab8c45"
      },
      "source": [
        "pip install nltk "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMhTdzmmajF4"
      },
      "source": [
        "# Kör denna cell för att ladda in biblioteken och sätta upp vår miljö\n",
        "import pandas as pd\n",
        "import nltk as tm\n",
        "from nltk.corpus import stopwords\n",
        "import wordcloud\n",
        "import matplotlib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Sätt upp visualiseringen\n",
        "%matplotlib inline\n",
        "matplotlib.pyplot.rcParams['figure.figsize'] = [10, 6]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF9Ed9J3ajF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97127b52-e313-4c78-ab66-4435506fcc62"
      },
      "source": [
        "tm.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5x0k0KsajF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a0a5b6-2bb4-4c7a-fefd-c7a7f4930afc"
      },
      "source": [
        "stopWords = set(stopwords.words('swedish'))\n",
        "stopWords"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alla',\n",
              " 'allt',\n",
              " 'att',\n",
              " 'av',\n",
              " 'blev',\n",
              " 'bli',\n",
              " 'blir',\n",
              " 'blivit',\n",
              " 'de',\n",
              " 'dem',\n",
              " 'den',\n",
              " 'denna',\n",
              " 'deras',\n",
              " 'dess',\n",
              " 'dessa',\n",
              " 'det',\n",
              " 'detta',\n",
              " 'dig',\n",
              " 'din',\n",
              " 'dina',\n",
              " 'ditt',\n",
              " 'du',\n",
              " 'där',\n",
              " 'då',\n",
              " 'efter',\n",
              " 'ej',\n",
              " 'eller',\n",
              " 'en',\n",
              " 'er',\n",
              " 'era',\n",
              " 'ert',\n",
              " 'ett',\n",
              " 'från',\n",
              " 'för',\n",
              " 'ha',\n",
              " 'hade',\n",
              " 'han',\n",
              " 'hans',\n",
              " 'har',\n",
              " 'henne',\n",
              " 'hennes',\n",
              " 'hon',\n",
              " 'honom',\n",
              " 'hur',\n",
              " 'här',\n",
              " 'i',\n",
              " 'icke',\n",
              " 'ingen',\n",
              " 'inom',\n",
              " 'inte',\n",
              " 'jag',\n",
              " 'ju',\n",
              " 'kan',\n",
              " 'kunde',\n",
              " 'man',\n",
              " 'med',\n",
              " 'mellan',\n",
              " 'men',\n",
              " 'mig',\n",
              " 'min',\n",
              " 'mina',\n",
              " 'mitt',\n",
              " 'mot',\n",
              " 'mycket',\n",
              " 'ni',\n",
              " 'nu',\n",
              " 'när',\n",
              " 'någon',\n",
              " 'något',\n",
              " 'några',\n",
              " 'och',\n",
              " 'om',\n",
              " 'oss',\n",
              " 'på',\n",
              " 'samma',\n",
              " 'sedan',\n",
              " 'sig',\n",
              " 'sin',\n",
              " 'sina',\n",
              " 'sitta',\n",
              " 'själv',\n",
              " 'skulle',\n",
              " 'som',\n",
              " 'så',\n",
              " 'sådan',\n",
              " 'sådana',\n",
              " 'sådant',\n",
              " 'till',\n",
              " 'under',\n",
              " 'upp',\n",
              " 'ut',\n",
              " 'utan',\n",
              " 'vad',\n",
              " 'var',\n",
              " 'vara',\n",
              " 'varför',\n",
              " 'varit',\n",
              " 'varje',\n",
              " 'vars',\n",
              " 'vart',\n",
              " 'vem',\n",
              " 'vi',\n",
              " 'vid',\n",
              " 'vilka',\n",
              " 'vilkas',\n",
              " 'vilken',\n",
              " 'vilket',\n",
              " 'vår',\n",
              " 'våra',\n",
              " 'vårt',\n",
              " 'än',\n",
              " 'är',\n",
              " 'åt',\n",
              " 'över'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "kk522-TkajF5"
      },
      "source": [
        "## Analys av Twitterdata från bokmässan\n",
        "\n",
        "Ni har blivit inhyrda som konsulter för en bokpublicist som vill att du ska ta reda på vilka teman och böcker som har fått mest uppmärksamhet på bokmässan i Göteborg 2016. \n",
        "\n",
        "Er uppgift är att via Twitterdata undersöka vilka ämnen som fått speciellt mycket uppmärksamhet för och under bokmässan och presentera ett förslag till företaget du arbetar med vad som är lämpliga debattämnen. \n",
        "\n",
        "Fokus här är alltså på att förstå data, vilket är en viktigt del av pre-processering inför mer avacerad dataanalys. \n",
        "\n",
        "**F1.** Vad för data är distinkt för twitter och vilken typ av pre-processing tror ni kommer behövas på den typen av data? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XXNpFhwoEqt"
      },
      "source": [
        "**F1: SVAR **\n",
        "\n",
        "Gå igenom varje tweet och se innehållet, organisera tweeten i grupper för att se vilken grupp är mest lockande.\n",
        "\n",
        "Efter det kan man se hur ofta ämnet förrekommer i samlingen, hur ofta den har blivit retweetad och vilken tid brukar folk tweeta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "v6sJGyUEajF6"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "Som alltid behöver vårt data städas, i detta fall är fokus att sortera bort data som antingen inte går att analysera eller inte är intressant från den råtextdata vi fått från Twitter. Den data som givits samlades in från Twitter från maj till september 2016.\n",
        "\n",
        "Er datafil finns i mappen data i laborationsrepositoriet och heter `twitter_book_fair_data.tsv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "lmueoYoxajF6"
      },
      "source": [
        "### Ladda data\n",
        "\n",
        "En `.tsv` fil betyder att det är en tab-separerad fil med tabelldata (jämfört med ; separerad som vi använt tidigare)\n",
        "\n",
        "**F2** Starta arbetet med att läsa in filen med read_csv() med följande parametrar:  encoding=\"utf-8\", sep=\"\\t\" och spara i en dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "8uQSj3Iwr6LU",
        "outputId": "87efae88-0af5-4da4-d59e-5705a401c6ea"
      },
      "source": [
        "#F2 läsa fil\n",
        "\n",
        "tweet_df= pd.read_csv(\"twitter_book_fair_data.tsv\", encoding=\"utf-8\", sep=\"\\t\")\n",
        "tweet_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>to_user_id</th>\n",
              "      <th>from_user</th>\n",
              "      <th>id</th>\n",
              "      <th>from_user_id</th>\n",
              "      <th>iso_language_code</th>\n",
              "      <th>source</th>\n",
              "      <th>profile_image_url</th>\n",
              "      <th>geo_type</th>\n",
              "      <th>geo_coordinates_0</th>\n",
              "      <th>geo_coordinates_1</th>\n",
              "      <th>created_at</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt @amiethekid: kvaellens avsnitt av raseriet ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ornellanizii</td>\n",
              "      <td>780663045701955584</td>\n",
              "      <td>701149297</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;tw...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tue sep 27 06:59:08 +0000 2016</td>\n",
              "      <td>1.474960e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maranatafoersamlingens monter paa bokmaessan v...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>strrawbuz</td>\n",
              "      <td>780658066073198592</td>\n",
              "      <td>163765933</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;tw...</td>\n",
              "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tue sep 27 06:39:21 +0000 2016</td>\n",
              "      <td>1.474958e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>idrotten blev en trygg zon under en jobbig ton...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>birgittajekblom</td>\n",
              "      <td>780655458407383040</td>\n",
              "      <td>72873310</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tue sep 27 06:28:59 +0000 2016</td>\n",
              "      <td>1.474958e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tillbakablick paa #bokmaessan #goeteborg del 1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>kimmkimselius</td>\n",
              "      <td>780654308002062336</td>\n",
              "      <td>65428329</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"https://about.twitter.com/products/tw...</td>\n",
              "      <td>http://pbs.twimg.com/profile_background_images...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tue sep 27 06:24:25 +0000 2016</td>\n",
              "      <td>1.474957e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt @flamman_: aha, vilken tid aer demon? hm, d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>annaherdy</td>\n",
              "      <td>780654122076962816</td>\n",
              "      <td>111971247</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"https://about.twitter.com/products/tw...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme17/bg.gif</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tue sep 27 06:23:41 +0000 2016</td>\n",
              "      <td>1.474957e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>rt @mxcartoons: nya tider kommenterar bokmaess...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zwepol</td>\n",
              "      <td>766966928837664768</td>\n",
              "      <td>2994150045</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sat aug 20 11:55:40 +0000 2016</td>\n",
              "      <td>1.471694e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>rt @viskot: apropaa #bokmaessan och det haer m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hannabergmans</td>\n",
              "      <td>766966926463668224</td>\n",
              "      <td>873555458</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sat aug 20 11:55:39 +0000 2016</td>\n",
              "      <td>1.471694e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>rt @charlieafnord: hej @bokmassangbg. kommer n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gnellriksson</td>\n",
              "      <td>766966850693566464</td>\n",
              "      <td>2233508656</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sat aug 20 11:55:21 +0000 2016</td>\n",
              "      <td>1.471694e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>rt @mxcartoons: nya tider kommenterar bokmaess...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hedvigkrook</td>\n",
              "      <td>766966686113071104</td>\n",
              "      <td>3065329706</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;tw...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sat aug 20 11:54:42 +0000 2016</td>\n",
              "      <td>1.471694e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>rt @dolf371: tystnad aer yttrandefrihet – #bok...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>zwepol</td>\n",
              "      <td>766966540155617285</td>\n",
              "      <td>2994150045</td>\n",
              "      <td>sv</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sat aug 20 11:54:07 +0000 2016</td>\n",
              "      <td>1.471694e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...          time\n",
              "0     rt @amiethekid: kvaellens avsnitt av raseriet ...  ...  1.474960e+09\n",
              "1     maranatafoersamlingens monter paa bokmaessan v...  ...  1.474958e+09\n",
              "2     idrotten blev en trygg zon under en jobbig ton...  ...  1.474958e+09\n",
              "3     tillbakablick paa #bokmaessan #goeteborg del 1...  ...  1.474957e+09\n",
              "4     rt @flamman_: aha, vilken tid aer demon? hm, d...  ...  1.474957e+09\n",
              "...                                                 ...  ...           ...\n",
              "9995  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
              "9996  rt @viskot: apropaa #bokmaessan och det haer m...  ...  1.471694e+09\n",
              "9997  rt @charlieafnord: hej @bokmassangbg. kommer n...  ...  1.471694e+09\n",
              "9998  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
              "9999  rt @dolf371: tystnad aer yttrandefrihet – #bok...  ...  1.471694e+09\n",
              "\n",
              "[10000 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "N86eQxITajF6"
      },
      "source": [
        "**F3** Inspektera den dataframe som skapats med lämpliga funktioner. Ta reda på följande:\n",
        "\n",
        "Hur ser den ut?\n",
        "Antal kolumner och rader?\n",
        "Datatyper?\n",
        "\n",
        "Glöm inte bort att när du utför operationer på en datafram så sparas ingenting om du inte skapar en variabel som du lagrar dina ändringar i! (alternativt skriver över den dataframe du har genom att sätta parametern inplace = True (default är False)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJUkj2ksiIF",
        "outputId": "d5232fb4-159a-4396-ec97-1e625ea190f1"
      },
      "source": [
        "#F3) Inspeltera dataframe\n",
        "\n",
        "#a) typer\n",
        "\n",
        "tweet_df.count\n",
        "#10000 rader och 13 kolumner, numeriskt(int) och text(string)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                                    text  ...          time\n",
              "0     rt @amiethekid: kvaellens avsnitt av raseriet ...  ...  1.474960e+09\n",
              "1     maranatafoersamlingens monter paa bokmaessan v...  ...  1.474958e+09\n",
              "2     idrotten blev en trygg zon under en jobbig ton...  ...  1.474958e+09\n",
              "3     tillbakablick paa #bokmaessan #goeteborg del 1...  ...  1.474957e+09\n",
              "4     rt @flamman_: aha, vilken tid aer demon? hm, d...  ...  1.474957e+09\n",
              "...                                                 ...  ...           ...\n",
              "9995  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
              "9996  rt @viskot: apropaa #bokmaessan och det haer m...  ...  1.471694e+09\n",
              "9997  rt @charlieafnord: hej @bokmassangbg. kommer n...  ...  1.471694e+09\n",
              "9998  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
              "9999  rt @dolf371: tystnad aer yttrandefrihet – #bok...  ...  1.471694e+09\n",
              "\n",
              "[10000 rows x 13 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ohe0pxYajF6"
      },
      "source": [
        "**F4** Finns det nullvärden i vårt dataset? Varför/varför inte?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bozlHal6t6HZ",
        "outputId": "be9bd432-3068-48bf-d1e9-01767e5efa09"
      },
      "source": [
        "#F4- nullvärden\n",
        "\n",
        "tweet_df.isnull().values.any()\n",
        "#Svar: Ja det finns, anledningen är att vissa har tillexempel inga profilbilder eller har inte taggat någon i tweeten.\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCvI7CU3ajF7"
      },
      "source": [
        "**F5.** Hur många tweets i vårt dataset är nämnanden av andra användare (alltså när `@twittername` finns med i tweeten) \n",
        "\n",
        "*Hint: Det kan vara till hjälp att använda funktionen `info()`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vIyKxfkx8Zp",
        "outputId": "a7774fb8-e081-4410-fe9c-12a44bfd2f56"
      },
      "source": [
        "#F5- tweets antal med nämnaden av andra användare\n",
        "\n",
        "tweet_df[\"to_user_id\"].count()\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "sdcmUWqKajF7"
      },
      "source": [
        "**F6.** En kolumn är speciellt intressant för vår **textanalys**, extrahera den från den dataframe vi lagrat all data i och skapa en variabel där du placerar denna data, döp variablen till `tweets_corpus`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsOggIyt3T_i",
        "outputId": "b38f5121-f6c9-4e8e-93e8-6d9aefc1cedb"
      },
      "source": [
        "#F6- textanalys\n",
        "\n",
        "tweets_corpus = tweet_df['text']\n",
        "tweets_corpus\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       rt @amiethekid: kvaellens avsnitt av raseriet ...\n",
              "1       maranatafoersamlingens monter paa bokmaessan v...\n",
              "2       idrotten blev en trygg zon under en jobbig ton...\n",
              "3       tillbakablick paa #bokmaessan #goeteborg del 1...\n",
              "4       rt @flamman_: aha, vilken tid aer demon? hm, d...\n",
              "                              ...                        \n",
              "9995    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9996    rt @viskot: apropaa #bokmaessan och det haer m...\n",
              "9997    rt @charlieafnord: hej @bokmassangbg. kommer n...\n",
              "9998    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9999    rt @dolf371: tystnad aer yttrandefrihet – #bok...\n",
              "Name: text, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "LIfuMtZsajF7"
      },
      "source": [
        "### Emojis\n",
        "\n",
        "På Twitter är det väldigt vanligt med emojis 👍 ✨ 🐫 🎉 🚀 🤘.\n",
        "\n",
        "Dessa kan innehålla mycket information som kan vara relevant för vår analys. Dock är det ofta svårt att analysera emojis med hjälp av vanliga verktug för NLP(Natural Language Processig). \n",
        "\n",
        "Vi behöver därför ta bort dessa ur vårt utvalda dataset som skapades i uppgiften ovan.\n",
        "\n",
        "Följande kod utför detta, ni behöver inte bry er om lambda just nu, men vi kommer gå igenom det lite senare i kursen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xxtFMo70ajF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bfc5a79-967a-4488-92a4-2e76be945af2"
      },
      "source": [
        "encode2ascii = lambda x: x.encode('ascii', errors='ignore').decode('utf-8')\n",
        "clean_tweets = tweets_corpus.apply(encode2ascii)\n",
        "clean_tweets"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       rt @amiethekid: kvaellens avsnitt av raseriet ...\n",
              "1       maranatafoersamlingens monter paa bokmaessan v...\n",
              "2       idrotten blev en trygg zon under en jobbig ton...\n",
              "3       tillbakablick paa #bokmaessan #goeteborg del 1...\n",
              "4       rt @flamman_: aha, vilken tid aer demon? hm, d...\n",
              "                              ...                        \n",
              "9995    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9996    rt @viskot: apropaa #bokmaessan och det haer m...\n",
              "9997    rt @charlieafnord: hej @bokmassangbg. kommer n...\n",
              "9998    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9999    rt @dolf371: tystnad aer yttrandefrihet  #bokm...\n",
              "Name: text, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "koJPAh3UajF8"
      },
      "source": [
        "**F7.** Hur påverkas kvaliteten på vår analys potentiellt av att ta bort alla emojis? Förklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIowYJHC4CJR"
      },
      "source": [
        "Genom att ta bort all emojis, länkar, förkortningar får vi tillgång till renare data och kan fokusera på innehållet av tweeten. Emojis kan vara svårt att hantera eftersom de kan tolkas olika och därför genom att tvätta datat får vi tillgågn till bättre kvalité. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "SGdc-slQajF8"
      },
      "source": [
        "### Ta bort URLs\n",
        "Det är också vanligt att man på Twitter länkar till olika webbplatser med hjälp av URL:er, när man gör textanalys på twitterdata är det vanligt att delar av dessa URL:er dyker upp som \"mest frekventa ord\" vilket påverkar vår analys negativs. Dessa behöver därför också tas bort."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qASVIUi0ajF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c363aeb5-6cd0-485a-f572-723387682b3d"
      },
      "source": [
        "clean_tweets = clean_tweets.str.replace(r'http\\S+', '')\n",
        "clean_tweets"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       rt @amiethekid: kvaellens avsnitt av raseriet ...\n",
              "1       maranatafoersamlingens monter paa bokmaessan v...\n",
              "2       idrotten blev en trygg zon under en jobbig ton...\n",
              "3        tillbakablick paa #bokmaessan #goeteborg del 1  \n",
              "4       rt @flamman_: aha, vilken tid aer demon? hm, d...\n",
              "                              ...                        \n",
              "9995    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9996    rt @viskot: apropaa #bokmaessan och det haer m...\n",
              "9997    rt @charlieafnord: hej @bokmassangbg. kommer n...\n",
              "9998    rt @mxcartoons: nya tider kommenterar bokmaess...\n",
              "9999    rt @dolf371: tystnad aer yttrandefrihet  #bokm...\n",
              "Name: text, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCLISNszajF8"
      },
      "source": [
        "**F8.** Hur kan borttagandet av URL:er pvåerkar analysen och dess kvalitet, förklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-5yDOzA5n2p"
      },
      "source": [
        "Som det nämndes ovan, får vi renare innehåll som ökar kvalitet på vår data. URL kan vara svår att hantera eftersom vi måste undersöka vad är det för länk, om det är rätt länk, om sidan som länkas till är lämpligt och även kontrollera så att det innehåller inga viruser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "WzE_vFuNajF8"
      },
      "source": [
        "### Funktion för att hitta mest frekventa ord \n",
        "\n",
        "Ett sätt att förstå hur olika metoder för pre-processing påverkar ett dataset kan man räkna de mest förekommande orden efter varje operation som utförs. Eftersom vi kommer vilja utföra denna räkning många gånger under arbetet är de lämpligt att skapa en funktion för det som vi kan anropa flera gånger.\n",
        "\n",
        "#### Vad är en Term Document Matrix (TDM)?\n",
        "\n",
        "En TDM är en tabell där antalet unika ord räknas för varje dokument. För att göra detta på vårt Twitterdata är det lämpligt att skapa en TDM där varje tweet är en egen vektor där varje element består av de ord som finns i den tweeten. En tweet med tre unika ord blir alltså en vektor med tre element. \n",
        "\n",
        "Nedanstående kod skapar denna TDM i form av en funktion med namn `create_term_document_matrix()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyj7-rAUajF9"
      },
      "source": [
        "**F9** Koden nedan är inte kommenterad, lägg in kommentarer som förklarar vad som sker i koden. (No hittar dokumentationen för CountVectorizer() [här](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) och en kort beskrivning med exempel [här](https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjVc_7ziajF9"
      },
      "source": [
        "#Skapas funktionen \"create_term_document_matrix\" som skapar en corpus som är \n",
        "#samling av skrivna texter och sätter min_df till 1 så att det börjar från index 1\n",
        "def create_term_document_matrix(corpus, min_df=1):\n",
        "  #Här skapas variabeln \"cves\", Countvectorizer skapar en matris för varje unik ord\n",
        "  #skapar två variabel min_df och stop_words och sätter de till min_df och stopWords\n",
        "    cvec = CountVectorizer(min_df=min_df, stop_words=stopWords)\n",
        "    #i variabeln tfmatrix läggs corpusen in och \"fitar\" båda variablarna och \n",
        "    #sedan retunerar den variablen tilbaka.\n",
        "    tfmatrix = cvec.fit_transform(corpus)\n",
        "    #Returnera från pandas dataframe genom att skapa variabeln \"data\"\n",
        "    #i variabeln data lags alla tfmatrixer från arraylisten\n",
        "    #i variabeln columns sparas hämtade get_feature_names()\n",
        "    return pd.DataFrame(data=tfmatrix.toarray(), columns=cvec.get_feature_names())"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrul6vICajF9"
      },
      "source": [
        "**F10** Testa vår nya funktion genom att skapa en TDM endast för de tre första raderna i `clean_tweets` som kan sorteras ut med `.head(3)` funktionen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP1lMF6kajF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "67a9ec1c-d885-4f7c-e014-0c3781c80230"
      },
      "source": [
        "#kod här..\n",
        "create_term_document_matrix(clean_tweets).head(3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>031</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>073996782</th>\n",
              "      <th>0739967827</th>\n",
              "      <th>08</th>\n",
              "      <th>08pol</th>\n",
              "      <th>09</th>\n",
              "      <th>099</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>1007</th>\n",
              "      <th>10misstagfoerfattaregoer</th>\n",
              "      <th>10pers</th>\n",
              "      <th>10s</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>1230</th>\n",
              "      <th>13</th>\n",
              "      <th>1300</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>1530</th>\n",
              "      <th>16</th>\n",
              "      <th>1600</th>\n",
              "      <th>1630</th>\n",
              "      <th>165679596</th>\n",
              "      <th>17</th>\n",
              "      <th>1700</th>\n",
              "      <th>1730</th>\n",
              "      <th>...</th>\n",
              "      <th>ytterligare</th>\n",
              "      <th>ytterst</th>\n",
              "      <th>yttervarvet</th>\n",
              "      <th>yttr</th>\n",
              "      <th>yttra</th>\n",
              "      <th>yttrande</th>\n",
              "      <th>yttrandefri</th>\n",
              "      <th>yttrandefrihet</th>\n",
              "      <th>yttrandefriheten</th>\n",
              "      <th>yttrandefrihetens</th>\n",
              "      <th>yttrandefrihetsdebatt</th>\n",
              "      <th>yttrandefrihetsexpert</th>\n",
              "      <th>yttrandefrihetsextremist</th>\n",
              "      <th>yttrandefrihetsfobiker</th>\n",
              "      <th>yttrandefrihetsfobikerna</th>\n",
              "      <th>yttrandefrihetsfraagor</th>\n",
              "      <th>yttrandefrihetsmaessan</th>\n",
              "      <th>yttrandefrihetsmontern</th>\n",
              "      <th>yttrandefrihetsscenen</th>\n",
              "      <th>yttrandefrihetstemat</th>\n",
              "      <th>yttranden</th>\n",
              "      <th>yttrat</th>\n",
              "      <th>yukiko</th>\n",
              "      <th>yvoeri</th>\n",
              "      <th>yvonne</th>\n",
              "      <th>zainab</th>\n",
              "      <th>zandra</th>\n",
              "      <th>zaralarsson</th>\n",
              "      <th>zaw</th>\n",
              "      <th>zawall</th>\n",
              "      <th>zedendahl</th>\n",
              "      <th>zetterlund</th>\n",
              "      <th>ziggy</th>\n",
              "      <th>zlatan</th>\n",
              "      <th>zoecormier</th>\n",
              "      <th>zombieseminariet</th>\n",
              "      <th>zon</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zpiff75</th>\n",
              "      <th>zweigbergk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 13244 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  01  02  03  ...  zombieseminariet  zon  zoo  zpiff75  zweigbergk\n",
              "0   0    0   0   0   0  ...                 0    0    0        0           0\n",
              "1   0    0   0   0   0  ...                 0    0    0        0           0\n",
              "2   0    0   0   0   0  ...                 0    1    0        0           0\n",
              "\n",
              "[3 rows x 13244 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMMdrygGajF9"
      },
      "source": [
        "**F11.** Hur många kolumner skapades i TDM:n?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0GSmwCfBRWD"
      },
      "source": [
        "SVAR: Det skapades 13244 kolumner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCm_VtcaajF-"
      },
      "source": [
        "För att hitta de mest frekvent förekommander orden i vår TDM behöver vi räkna ord. Det är också lämpligt med en visualisering över dessa vanligast förekommande ord. Även detta kommer vi behöva göra flera gånger och därför är det återigen lämpligt att definiera en funktion `plot_top_words()` som både räknar och plottar orden i ett stapeldiagram. \n",
        "\n",
        "**F12** I nedanstående cell är funktionen definierad, men koden är återigen inte kommenterad, skapa kommentarer (eller skriv i en markdowncell) som förklarar vad funktionen gör. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAgs4atDajF-"
      },
      "source": [
        "#Skapas funktione plot_top_words med tre variabel: tweets, num_word_instances, top_words\n",
        "def plot_top_words(tweets, num_word_instances, top_words):\n",
        "#skapas variabeln tdm_df och skapar matris av tweets och sätter min_df på 2(index)\n",
        "    tdm_df = create_term_document_matrix(tweets, min_df=2)\n",
        "    #skapas variabeln word_frequencies med if sats för att kolla om x finns o kolument \n",
        "    #och om längden på listan är större än 1 och slutligen summerar all värde\n",
        "    word_frequencies = tdm_df[[x for x in tdm_df.columns if len(x) > 1]].sum()\n",
        "    #skapas sorted_words varibeln där den sorterar values och\n",
        "    #sätter sorteringen på fallande ordning så att de största värdena i kolumnen är högst upp \n",
        "    sorted_words = word_frequencies.sort_values(ascending=False)\n",
        "    #Skapas top_sorted_words variabel och \n",
        "    top_sorted_words = sorted_words[:num_word_instances]\n",
        "    top_sorted_words[:top_words].plot.bar()\n",
        "    return top_sorted_words"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKf5b6IeajF-"
      },
      "source": [
        "Nu kan vi använda `plot_top_words()` funktionen för att räkna ut de mest förekommande orden i hela vårt corpus, viktigt att ha tålamod dock för det kan ta ett tag. Nedanstående kod utför beräkningen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CShvTyvajF-"
      },
      "source": [
        "top_words = plot_top_words(clean_tweets, 50, 30)\n",
        "top_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmQE4K2PajF_"
      },
      "source": [
        "**F13** Hur många gånger måste ett ord finnas i corpuset för att finnas med i `top_words` så som den är skriven ovan?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHCxoDUeajF_"
      },
      "source": [
        "**F14.** Hur många ord plottas i stapeldiagrammet? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "f4wg7zCSajF_"
      },
      "source": [
        "### Små bokstäver\n",
        "\n",
        "Nästa steg i pre-processingen av vårt dataset (vårt corpus) är att göra om alla bokstäver till små. \n",
        "\n",
        "**F15** \n",
        "\n",
        "a.Utför ändringen att alla stora bokstäver blir små bokstäver i `clean_tweets` och spara i en ny variabel kallad `tweets_lowered`\n",
        "\n",
        "b.Varför vill man göra det för vår analys?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-iLcu_pajF_"
      },
      "source": [
        "**F16** Räkna ut en ny variabel med de mest förekommander (frekventa) orden, döp den till `top_words_lowered`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-TPiW1oajF_",
        "outputId": "136c1552-907b-4adb-cc6b-aa79a6b87cd9"
      },
      "source": [
        "#Skriv klart denna kodcell för F1.16\n",
        "\n",
        "top_words_lowered = ...\n",
        "top_words_lowered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRWQ-7ByajGB"
      },
      "source": [
        "**F17.** Har något förändrats, vad? Förklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "hpWdIPRSajGB"
      },
      "source": [
        "För att underlätta att jämföra vad våra ansträngningar får för resultat kan det vara bra att enkelt kunna jämföra olika listor med top_words.\n",
        "\n",
        "**F18** Skapa en ny dataframe som har två kolumner, en med de 20 mest frekventa orden från`top_words` och en med de 20 mest frekventa orden från `top_word_lowered`. Döp kolumnerna till `Top tweeted clean`och  `Top tweeted lowered`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K-nmjqIajGB"
      },
      "source": [
        "pd.DataFrame({\n",
        "    'Top tweeted clean': top_words[0:20].index,\n",
        "    'Top tweeted lowered': top_words_lowered[0:20].index\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "oHiDwJ9DajGB"
      },
      "source": [
        "Ett annnat sätt att göra ungefär samma sak, fast lite mer automatiskt är nedanstående kod som också jämför de första 20 orden. Gör om den så att den istället för att jämföra de 20 mest frekventa orden, jämför de ord som är minst förekommande i de två listorna `top_words`och `top_words_lowered`.\n",
        "\n",
        "**F19** Vad returnerar nedanstående kodrad om de två listor som jämförs är identiska? Vad returneras om de inte är identiska?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic0nvyQbajGC"
      },
      "source": [
        "set(top_words[0:20].index) - set(top_words_lowered[0:20].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrfxdRl8ajGC"
      },
      "source": [
        "### Korta ord\n",
        "\n",
        "Korta ord har ofta inte någon egentlig betydelse, alltså behöver vi inte dessa ord. Typiska sådana ord kan vara ja, jo eller nej. Vi bestämmer oss för att alla ord som är kortare än 3 bokstäver inte innehar någon betydelse i vår analys och tar därmed bort dem. \n",
        "\n",
        "**F20** Ta bort alla ord med färre bokstäver än 3(HINT: [regular expressions](https://docs.python.org/3/howto/regex.html)), lägg den nya listan med ord (som inte innehåller ord med färre bokstäver än 3) i en variabel med namn `tweets_low_no_small`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_bu58N8ajGC"
      },
      "source": [
        "tweets_low_no_small = ...#din kod här"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMkiDio1ajGC"
      },
      "source": [
        "#Skapar ny topplista utan korta ord\n",
        "top_words_low_no_small = plot_top_words(tweets_low_no_small, 50, 30)\n",
        "top_words_low_no_small"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0SBbecoajGC"
      },
      "source": [
        "**F21.** Efter att korta ord tagits bort, hur många gånger måste ett ord förekomma i vårt corpus för att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "7C5pg93tajGC"
      },
      "source": [
        "### Betydelselösa ord\n",
        "\n",
        "Stop words är andra ord som inte är korta men som ändå inte har betydelse, dessa kan vara lite besvärligare att identifiera och ta bort. En möjlighet är att helt enkelt skapa en lista med sådana ord och sedan använda den listan för att filtrera ut orden ur ett corpus. Vi har ju redan tagit bort alla ord med färre bokstäver än 3, så sådana behöver vi inte lägga in i listan. \n",
        "\n",
        "Nedan är ett exempel på en lista med stoppord som är betydelselösa. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APmKArtvajGD"
      },
      "source": [
        "my_stop_words = [\"och\", \"det\", \"att\", \"i\", \"en\", \"jag\", \"hon\", \n",
        "                \"som\", \"han\", \"paa\", \"den\", \"med\", \"var\", \"sig\", \n",
        "                \"foer\", \"saa\", \"till\", \"aer\", \"men\", \"ett\", \n",
        "                \"om\", \"hade\", \"de\", \"av\", \"icke\", \"mig\", \"du\", \n",
        "                \"henne\", \"daa\", \"sin\", \"nu\", \"har\", \"inte\", \n",
        "                \"hans\", \"honom\", \"skulle\", \"hennes\", \"daer\", \n",
        "                \"min\", \"man\", \"ej\", \"vid\", \"kunde\", \"naagot\", \n",
        "                \"fraan\", \"ut\", \"naer\", \"efter\", \"upp\", \"vi\", \n",
        "                \"dem\", \"vara\", \"vad\", \"oever\", \"aen\", \"dig\", \n",
        "                \"kan\", \"sina\", \"haer\", \"ha\", \"mot\", \"alla\", \n",
        "                \"under\", \"naagon\", \"eller\", \"allt\", \"mycket\", \n",
        "                \"sedan\", \"ju\", \"denna\", \"sjaelv\", \"detta\", \n",
        "                \"aat\", \"utan\", \"varit\", \"hur\", \"ingen\", \"mitt\", \n",
        "                \"ni\", \"bli\", \"blev\", \"oss\", \"din\", \"dessa\", \n",
        "                \"naagra\", \"deras\", \"blir\", \"mina\", \"samma\", \n",
        "                \"vilken\", \"er\", \"saadan\", \"vaar\", \"blivit\", \n",
        "                \"dess\", \"inom\", \"mellan\", \"saadant\", \"varfoer\", \n",
        "                \"varje\", \"vilka\", \"ditt\", \"vem\", \"vilket\", \n",
        "                \"sitta\", \"saadana\", \"vart\", \"dina\", \"vars\", \n",
        "                \"vaart\", \"vaara\", \"ert\", \"era\", \"vilka\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "23GFNjo2ajGD"
      },
      "source": [
        "När vi skapat vår lista är det dags att skapa en funktion som tar bort dessa från ett dokument. Denna funktion är kodad i cellen nedan. (Igen strunta i lambda för tillfället.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh5zKFYMajGD"
      },
      "source": [
        "remove_stopwords = lambda x: ' '.join(y for y in x.split() if y not in my_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ8fFldkajGD"
      },
      "source": [
        "Funktionen ovan tar alltså bort stoppord från ett dokument (alltså en tweet), för att ta bort stoppord från hela vårt corpus kan funktionen `.apply()`användas. \n",
        "\n",
        "**F22.** Skriv den kod som tar bort alla stoppord från `tweets_low_no_small` och skapar en ny variabel `tweets_low_no_small_stopwords` för corpuset utan stoppord."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v-zPM1VajGD"
      },
      "source": [
        "tweets_low_no_small_stopwords = ...#din kod här"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDnfwU8HajGD"
      },
      "source": [
        "top_words_low_no_small_stopwords = plot_top_words(tweets_low_no_small_stopwords, 50, 30)\n",
        "top_words_low_no_small_stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpxS_XaOajGD"
      },
      "source": [
        "**F23.** Efter att stopporden tagits bort, hur många gånger måste ett ord förekomma i vårt corpus för att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "ofc7xaJvajGE"
      },
      "source": [
        "**F24.** Vad är skillnaderna mellan de frekvent förekommande orden i jämförelse med våra tidigare listor? Skriv den kod som jämför dessa tre listor `top_words_lowered`, `top_words_low_no_small` and `top_words_low_no_small_stopwords`, titta på de första 20 orden i listorna.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "8F_kNrkpajGE"
      },
      "source": [
        "### Visualisering och rekommendation\n",
        "\n",
        "Dags att visualisera vårt resultat och övertyga vår klient om att vi hittat de bästa debattämnena för dem! Här gör vi det genom att skapa ett word cloud där de mest frekventa orden syns bäst. \n",
        "\n",
        "Nedanstående kod skapar ett ordmoln för `top_words_low_no_small_stopwords`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn_I5Vh4ajGE"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "wordcloud = WordCloud(max_font_size=40)\n",
        "wordcloud.fit_words(top_words_no_small_stopwords.to_dict())\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZESLvEFajGE"
      },
      "source": [
        "**F25** Ändra i tidigare kod hur många gånger ett ord minst måste finnas för att det ska inkluderas i ordmolnet. Vad förändras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "Xb7OITVPajGE"
      },
      "source": [
        "**F26** När du tittar på ordmolnet, är det fler ord som borde vara stoppord? Ange några stycken och förklara varför de bör tas bort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "hCHbUQnRajGE"
      },
      "source": [
        "**F27.** Vilket tema rekommenderar ni att publicisten ska ha som debattämne? Förklara svaret. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "lHauS6fLajGE"
      },
      "source": [
        "**F28.** Ni har nu arbetat med textdata, hur är det annorlunda när det gäller pre-processing jämfört med annan typ av data som är av mer numerisk eller kategorisk karaktär?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQH0K-evajGF"
      },
      "source": [
        "---\n",
        "*När ni besvarat samtliga frågor och all er kod fungerar i enlighet med instruktioner*, spara ert arbete som HTML och ladda upp på Studium för laboration 2, eller länka till er Notebook på Collaboratory. \n",
        "\n",
        "** Glöm inte att versionshantera i GitHub så att jag kan följa ert arbete!** \n",
        "\n",
        "Lycka till!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l2OWa4SajGF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}